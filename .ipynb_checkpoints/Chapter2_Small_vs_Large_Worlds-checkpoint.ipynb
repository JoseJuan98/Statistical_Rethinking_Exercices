{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Chapter 2 - Small Worlds vs Large Wolrds\n",
    "\n",
    "The **Small World** represents the scientific model itself, and the **Large World**\n",
    "represents the broader context in which one deploys a model.\n",
    "\n",
    "**Bayesian inference** is just counting and comparing of possibilities. Consider\n",
    "by analogy Jorge Luis Borges’ short story “The Garden of Forking Paths.”\n",
    "In order to make good inference about what actually happened, it helps to consider\n",
    " everything that could have happened. A Bayesian analysis is a garden of forking data,\n",
    " in which alternative sequences of events are cultivated.\n",
    "\n",
    "**The approach cannot guarantee a correct answer**, on large world terms. But it can\n",
    "guarantee the best possible answer, on small world terms, that could be derived\n",
    "from the information fed into it.\n",
    "\n",
    "The goal of the Bayesian approach is to figure out which of the conjectures for a\n",
    "certain context is **the most plausible**, given some evidence (data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By comparing these counts, we have part of a solution\n",
    "for a way to rate the relative plausibility of each conjecture.\n",
    "But it’s only a part of a solution, because in order to compare these counts\n",
    "we first have to decide how many ways each conjecture could itself be realized.\n",
    "We might argue that when we have no reason to assume otherwise, we can just consider\n",
    " each conjecture equally plausible and compare the counts directly, **Principle of Indifference**.\n",
    " But often we do have reason to assume otherwise.\n",
    "\n",
    "> ***Principle of indifference***: When there is no reason to say that one conjecture is more plausible\n",
    "> than another, weigh all of the conjectures equally.\n",
    "\n",
    "To grasp a solution, suppose we’re willing to say each conjecture is equally plausible\n",
    "at the start. Then, we just compare the counts of ways\n",
    "in which each conjecture is compatible with the observed data. So, comparing them can suggest\n",
    "that ones are more plausible, than others. Since these are our initial counts, and\n",
    "probably they are going to update later, they are labeled **prior**.\n",
    "\n",
    "Then when we get more evidence or observations, we can update the conjectures' plausibility.\n",
    "Only if they new data is independent of the previous data,\n",
    "> To update the plausibility ***p*** of  a conjecture ***C*** that is produced in ***W<sub>prior</sub>***\n",
    "> ways based on previous data ***D<sub>prior</sub>*** after providing more evidence ***D<sub>new</sub>***\n",
    "> is as follows:\n",
    ">\n",
    "> $\\Large P_c \\propto W_{prior} \\times W_{new} $\n",
    "\n",
    "Why multiplication? Because it's a shortcut for counting all possible paths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## From counting to probability\n",
    "\n",
    "It’s hard to use these counts though, so almost always they are standardized in a way that\n",
    "transforms them into probabilities.\n",
    "\n",
    "The meaning would be the same, it’s just the relative values that matter. Second,\n",
    "as the amount of data grows, the counts will very quickly grow very large and become difficult\n",
    "to manipulate.\n",
    "\n",
    "Then, for any value p can take, we judge the plausibility of that value p\n",
    "as proportional to the number of ways it can get through the garden of forking data.\n",
    "Finally, we construct probabilities by standardizing the plausibility so that the sum of\n",
    "the plausibilities for all possible conjectures will be one. All you need to do in order to\n",
    "standardize is to add up all of the products, one for each value p can take, and then divide each\n",
    "product by the sum of products:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being ***p*** the proportion of a feature,\n",
    "\n",
    "\\begin{align*}\n",
    "\\Large P_p={\\frac {W_{{p}_{new}} \\times P_{prior}}{\\sum \\small products}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Example 2.1\n",
    "There is a bag with four marbles, and we only know that they are <span style=\"color:blue\">blue [B]</span> and\n",
    "<span style=\"color:grey\">white [W]</span>. A marble is picked from the bag putting it back after finishing, after\n",
    "doing this four times we got the sequence [<span style=\"color:blue\">B</span> <span style=\"color:grey\">W</span> <span style=\"color:blue\">B</span>] .\n",
    "\n",
    "So if ***p*** is defined as the proportion of marbles that are blue, for [<span style=\"color:blue\">B </span><span style=\"color:grey\">W W W</span>]\n",
    "with ***D<sub>new</sub>*** = [<span style=\"color:blue\">B</span> <span style=\"color:grey\">W</span> <span style=\"color:blue\">B</span>],\n",
    "we can say that:\n",
    "\n",
    "> plausability of ***p*** after ***D<sub>new</sub>*** $\\propto$ was ***p*** can produce\n",
    "> ***D<sub>new</sub>*** $\\times$ prior plausability of ***p***\n",
    "\n",
    "The above just means that for any value p can take, we judge the plausibility of that value p\n",
    "as proportional to the number of ways it can get through the garden of forking data.\n",
    "\n",
    "| Composition | p (prop.) | Ways (W) | Plausability (P) |\n",
    "| --- | --- | --- | --- |\n",
    "| [ <span style=\"color:grey\">W W W W</span> ] | 0 | 0 | 0 |\n",
    "| [ <span style=\"color:blue\">B </span><span style=\"color:grey\">W W W</span> ] | 0.25 | 3 | 0.15 |\n",
    "| [ <span style=\"color:blue\">B B</span><span style=\"color:grey\"> W W</span> ] | 0.5 | 8 | 0.4 |\n",
    "| [ <span style=\"color:blue\">B B B </span><span style=\"color:grey\">W</span> ] | 0.75 | 9 | 0.45 |\n",
    "| [ <span style=\"color:blue\">B B B B</span> ] | 1 | 0 | 0 |\n",
    "\n",
    "* A conjectured proportion of blue marbles, p, is usually called a ***parameter*** value.\n",
    "It’s just a way of indexing possible explanations of the data.\n",
    "* The relative number of ways that a value p can produce the data is usually called\n",
    "a ***likelihood***. It is derived by enumerating all the possible data sequences that\n",
    "could have happened and then eliminating those sequences inconsistent with the\n",
    "data.\n",
    "* The prior plausibility of any specific p is usually called the ***prior probability***.\n",
    "* The new, updated plausibility of any specific p is usually called the ***posterior\n",
    "probability***.\n",
    "## Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*2.1.1- How to calculate this plausibilities of the example 2.1 in Python?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.15, 0.4 , 0.45, 0.  ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ways=np.array([0,3,8,9,0])\n",
    "# Prior plausibility of p is 1 (it didn't change). So,\n",
    "Ways/Ways.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1 Building a model\n",
    "By working with probabilities instead of raw counts, Bayesian inference is made much\n",
    "easier, but it looks much harder.\n",
    "\n",
    "To get the logic moving, we need to make assumptions, and these assumptions constitute\n",
    "the model. Designing a simple Bayesian model benefits from a design loop with three steps.\n",
    "1. Data story: Motivate the model by narrating how the data might arise.\n",
    "2. Update: Educate your model by feeding it the data.\n",
    "3. Evaluate: All statistical models require supervision, leading possibly to model revision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1.1. A data story\n",
    "\n",
    "Bayesian data analysis usually means producing a story for how the\n",
    "data came to be. This story may be descriptive, specifying associations that can be used to\n",
    "predict outcomes, given observations. Or it may be causal, a theory of how some events\n",
    "produce other events.\n",
    "\n",
    "Typically, any story you intend to be causal may also be descriptive.\n",
    "But many descriptive stories are hard to interpret causally. But all data stories are complete,\n",
    "in the sense that they are sufficient for specifying an algorithm for simulating new data.\n",
    "\n",
    "### 2.1.2 Bayesian updating\n",
    "\n",
    "Using the evidence to decide among different possible conjectures, like the marbles on the bag previously.\n",
    "ach possible proportion may be more or less plausible, given the evidence.\n",
    "A Bayesian model begins with one set of plausibilities assigned to each of these possibilities.\n",
    "These are the prior plausibilities. Then it updates them in light of the data, to produce the\n",
    "posterior plausibilities. This updating process is a kind of learning, called ***Bayesian updating***.\n",
    "\n",
    "Notice that every updated set of plausibilities becomes the initial plausibilities for the\n",
    "next observation. Every conclusion is the starting point for future inference. However, this\n",
    "updating process works backwards, as well as forwards.\n",
    "\n",
    "Given the final set of plausibilities, it is possible\n",
    "to mathematically divide out the observation, to infer the previous plausibility curve. So the\n",
    "data could be presented to your model in any order, or all at once even. In most cases, you\n",
    "will present the data all at once, for the sake of convenience. But it’s important to realize that\n",
    "this merely represents abbreviation of an ***iterated learning process***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1.3 Evaluate\n",
    "The Bayesian model learns in a way that is demonstrably optimal, provided\n",
    "that the real, large world is accurately described by the model. This is to say that your\n",
    "Bayesian machine guarantees perfect inference, within the small world. No other way of\n",
    "using the available information, and beginning with the same state of information, could do\n",
    "better.\n",
    "\n",
    "However, the calculations may malfunction, so results always have to be checked. And if\n",
    "there are important differences between the model and reality, then there is no logical\n",
    "guarantee of large world performance. And even if the two worlds did match, any particular\n",
    "sample of data could still be misleading. So it’s worth keeping in mind at least two cautious principles:\n",
    "\n",
    "1. *First, the model’s certainty is no guarantee that the model is a good one.*\n",
    "2. *Supervise and critique your model’s work.*\n",
    "\n",
    "Moreover, models do not need to be exactly true in order to produce highly precise and useful inferences.\n",
    "This is because models are essentially information processing machines, and there are some surprising aspects of\n",
    "information that cannot be easily captured by framing the problem in terms of the truth of\n",
    "assumptions.\n",
    "\n",
    "Instead, the objective is to check the model’s adequacy for some purpose. This usually\n",
    "means asking and answering additional questions, beyond those that originally constructed\n",
    "the model. Both the questions and answers will depend upon the scientific context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Components of the model\n",
    "Consider three different kinds of things we counted in the previous sections.\n",
    "1. The number of ways each conjecture could produce an observation\n",
    "2. The accumulated number of ways each conjecture could produce the entire data\n",
    "3. The initial plausibility of each conjectured cause of the data\n",
    "\n",
    "Each of these things has a direct analog in conventional probability theory. And so the usual way we build a statistical model involves\n",
    "choosing distributions and devices for each that represent the relative numbers of ways things can happen.\n",
    "\n",
    "\n",
    "1. Variables. Variables are just symbols that can take on different values. In a scientific context, \n",
    "variables include things we wish to infer, such as proportions and rates, as well as things we might observe, the data. The first variable is our target of inference, *p*, *e.g. the proportion of marbles in the bag*. This variable cannot be observed. Unobserved variables are usually called ***parameters***. But while *p* itself is unobserved, we can infer it from the other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Definitions. Once we have all the variables we need to define each, we build a model that relates the variables to one to another. The\n",
    "goal is count all the ways the data could arise, given the assumptions. \n",
    "    1. ***Observed variables***. Define how plausible any combination of this variables is. Each specific value of ***p*** corresponds to aspecific plausibility of the data. In conventional statistics, a distribution function assigned to an observed variable is usually landcalled a likelihood. That term has special meaning in non-Bayesian statistics, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *When we observe a sample of variables, we need to say how likely that exact sample is, out of the universe of potential samples of the same length.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.2\n",
    "Suppose you have a globe representing our planet, the Earth. This version of the world is small enough to hold in your hands. You are curious how much of the surface is covered in water. You adopt the following strategy: You will toss the globe up in the air. When you catch it, you will record whether or not the surface under your right index finger is water or land. Then you toss the globe up in the air again and repeat the procedure. This strategy generates a sequence of surface samples from the globe, where *W* indicates water and *L* indicates land.\n",
    "\n",
    "In this case, once we add our assumptions that (1) every toss is independent of the other tosses and (2) the probability of W is the same on every toss, probability theory provides a unique answer, known as the binomial distribution. This is the common “coin tossing” distribution. And so the probability of observing W waters and L lands, with a probability p of water on each toss, is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\Large Pr(W, L|p)={\\frac {(W + L)!}{W!L!}}p^W(1-p)^L\n",
    "\\end{align*}\n",
    "\n",
    "> The counts of “water” W and “land’ L are distributed binomially, with prob-\n",
    "ability p of “water” on each toss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binom probability mass function \n",
    "\n",
    "\\begin{align*}\n",
    "\\Large f(k)={{n}\\choose{k}}p^k(1-p)^{n-k},\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}  k \\in \\{0, 1,..., n\\} , 0 \\leq p \\leq  1 \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Being $n$ the size of the sample or the *#samples*, $k$ the #times that a value has been selected in the sample, and $p$ the probability of that variable.\n",
    "\n",
    "Binom takes $n$ and $p$ as shape parameters, where $p$ is the probability of a single success $1 - p$ and is the probability of a single failure.\n",
    "\n",
    "The probability mass function above is defined in the “standardized” form. To shift distribution use the loc parameter. Specifically, ```binom.pmf(k, n, p, loc)``` is identically equivalent to ```binom.pmf(k - loc, n, p)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How compute compute the likelihood of the data—six W’s in nine tosses—under any value of p with?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16406250000000006"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.binom.pmf(k=6, n=9, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That number is the relative number of ways to get six water, holding $p$ at 0.5 and $N = W + L$ at nine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['W','L','W','W','W','L','W','L','W']\n",
    "# TODO LATER: it can be check the likelihood of each\n",
    "\n",
    "k,n = 0, 0\n",
    "p = 0.5\n",
    "x=[]\n",
    "for d in data:\n",
    "    n+=1\n",
    "    if d == 'W':\n",
    "        k+=1\n",
    "        x.append(stats.binom.pmf(k=k, n=n, p=p))\n",
    "    #print(k,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#n, p = 10, 0.5\n",
    "#x = np.arange(stats.binom.ppf(0.01, n, p), \n",
    "#              stats.binom.ppf(1, n, p))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, stats.binom.pmf(x, n, p), label='binom pmf')\n",
    "plt.title('Likelihood of water')\n",
    "plt.xlabel('proportion of water')\n",
    "plt.ylabel('plausability');\n",
    "#ax.vlines(x, 0, stats.binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import s from s\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
